{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:  [0.03372386 0.98923099 0.02554182 0.31245677]  gave max value of:  0.8317881316882177\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from scipy.stats import norm\n",
    "from warnings import catch_warnings, simplefilter\n",
    "\n",
    "def f(X):\n",
    "    return -X[:,0] + (X[:,1]-X[:,2])*np.cos(X[:,0]) - X[:,3]**2\n",
    "\n",
    "X_range = [(0,1), (0,1), (0,1), (0,1)]\n",
    "X = np.zeros((10000,len(X_range)))\n",
    "for i,lims in enumerate(X_range):\n",
    "    X[:,i] = np.random.uniform(lims[0],lims[1],10000)\n",
    "    \n",
    "Y = f(X)\n",
    "X_opt = X[Y.argmax(),:]\n",
    "\n",
    "print(\"Inputs: \", X_opt, \" gave max value of: \", Y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes estimate:  [0.05813662 0.93671219 0.00506352 0.28746649]  with true value  [0.78930108]\n",
      "True optimal:  [0.03372386 0.98923099 0.02554182 0.31245677]  with true value  [0.83178813]\n"
     ]
    }
   ],
   "source": [
    "def get_random_samples(X_range, n_random):\n",
    "    X = np.zeros((n_random, len(X_range)))\n",
    "    for i,lims in enumerate(X_range):\n",
    "        X[:,i] = np.random.uniform(lims[0],lims[1],n_random)\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def expected_improvement(X, X_sample, y_sample, model):\n",
    "    \"\"\"Return EI at each point in X.\n",
    "    \n",
    "    Computes EI at points X based on sampled data X_sample and Y_sample\n",
    "    \"\"\"\n",
    "    with catch_warnings():\n",
    "        # Ignore some weird sklearn errors in prediction\n",
    "        simplefilter(\"ignore\")\n",
    "        mu, sigma = model.predict(X, return_std=True)  # Get mean and variance at X\n",
    "        opt = y_sample.max()  # Current optimal\n",
    "        mu = mu.reshape(-1,1)\n",
    "        sigma = sigma.reshape(-1,1)\n",
    "\n",
    "        imp = mu - opt  # Improvement is the mean for a given x minus the current optimal\n",
    "        Z = imp / sigma  # Convert that to a z-score\n",
    "                \n",
    "        # This basically integrates from -inf up to Z and factors in the probability of actually\n",
    "        # getting the improvement value imp. We want the optimal expected improvement not just the \n",
    "        # highest best-case improvement.\n",
    "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        ei[sigma == 0.0] = 0.0\n",
    "\n",
    "        return ei\n",
    "    \n",
    "\n",
    "def opt_acquisition(X_sample, X_range, y_sample, model, n_surrogate):\n",
    "    \"\"\"Returns the X sample that optimizes the acquisition function\"\"\"\n",
    "    X = get_random_samples(X_range, n_surrogate)\n",
    "    scores = expected_improvement(X, X_sample, y_sample, model)\n",
    "    return X[scores.argmax(), :].reshape(1,-1)\n",
    "\n",
    "\n",
    "def bayes_opt(objective, n_random, n_bayes, X_range, n_surrogate=100):\n",
    "    \"\"\"Perform Bayesian optimization on the objective function.\n",
    "    \n",
    "    Args:\n",
    "        objective(function): The objective function to maximize.\n",
    "        n_random(int): The number of random samples to gather before\n",
    "            starting the bayesian optimization loops.\n",
    "        n_bayes(int): The number of Bayesian optimization loops to run.\n",
    "        X_range(list): List of (low_bound, up_bound) tuples giving the range\n",
    "            for each of the variables of the objective function.\n",
    "        n_surrogate(int, optional): The number of random samples to evaluate\n",
    "            on the surrogate model before evaluating the best option on the \n",
    "            objective function. Default 100.\n",
    "            \n",
    "    Returns:\n",
    "        List of length n_inputs containing the inputs to the objective function\n",
    "        that maximizes the return value.\n",
    "    \"\"\"\n",
    "    X_sample = get_random_samples(X_range, n_random)\n",
    "    y_sample = objective(X_sample).reshape(-1,1)\n",
    "        \n",
    "    model = GaussianProcessRegressor()\n",
    "    \n",
    "    for _ in range(n_bayes):\n",
    "        # Fit model to current data\n",
    "        model.fit(X_sample, y_sample)\n",
    "\n",
    "        # Find next x that optimizes expected improvement\n",
    "        x = opt_acquisition(X_sample, X_range, y_sample, model, n_surrogate)\n",
    "        \n",
    "        # Evaluate that x\n",
    "        y = objective(x)\n",
    "                \n",
    "        X_sample = np.vstack((X_sample, x))\n",
    "        y_sample = np.vstack((y_sample, y))\n",
    "        \n",
    "    plt.hist(X_sample)\n",
    "    plt.show()\n",
    "    return X_sample[y_sample.argmax()]\n",
    "    \n",
    "        \n",
    "X_range = [(0,1), (0,1), (0,1), (0,1)]\n",
    "X_bayes = bayes_opt(f, 5, 100, X_range)\n",
    "\n",
    "print(\"Bayes estimate: \", X_bayes, \" with true value \", f(X_bayes.reshape(1,-1)))\n",
    "print(\"True optimal: \", X_opt, \" with true value \", f(X_opt.reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
